{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bert.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1jrbl5si8zQfbcFQP1VqYPYzOjWVbqMWV","authorship_tag":"ABX9TyMx0KxGMjAwGD9dyHlzq+Qi"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfO6VGdOKMU1","executionInfo":{"status":"ok","timestamp":1606896711331,"user_tz":-540,"elapsed":2933,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}},"outputId":"785df3d6-f10e-43ae-e6e2-802782e7d94f"},"source":["!pip install transformers"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g0-MMO56KO1h","executionInfo":{"status":"ok","timestamp":1606896718068,"user_tz":-540,"elapsed":1486,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}}},"source":["# Libraries\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch\n","\n","# Preliminaries\n","\n","from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n","\n","# Models\n","\n","import torch.nn as nn\n","from transformers import BertTokenizer, BertForSequenceClassification\n","\n","# Training\n","\n","import torch.optim as optim\n","\n","# Evaluation\n","\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDYcLrs3KSsi","executionInfo":{"status":"ok","timestamp":1606896720626,"user_tz":-540,"elapsed":786,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}},"outputId":"f2b8fd0f-6a27-4569-bd0e-6b5d343f1efc"},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lgjjKZM-KVDM","executionInfo":{"status":"ok","timestamp":1606896722884,"user_tz":-540,"elapsed":1218,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"aO4PL_cMKXgQ","executionInfo":{"status":"ok","timestamp":1606896728229,"user_tz":-540,"elapsed":3238,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}}},"source":["# Model parameter\n","MAX_SEQ_LEN = 128\n","PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n","UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n","\n","# Fields\n","\n","label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n","id_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n","                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n","response_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n","                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n","fields = [('label', label_field), ('response', response_field)]\n","# test_fields = [('id', id_field), ('response', response_field)]\n","\n","# TabularDataset\n","\n","train, valid, test = TabularDataset.splits(path='/content/drive/MyDrive',train='train.csv', validation='valid.csv',\n","                                           test='test.csv', format='CSV', fields=fields, skip_header=True)\n","test_data = pd.read_csv('/content/drive/MyDrive/test_final.csv', encoding=\"ISO-8859-1\")\n","test_data.to_csv('/content/test_final.csv', index=False)\n","test_final = TabularDataset(path='/content/test_final.csv', format='CSV', \n","                                   fields=fields, skip_header=True)\n","\n","# # Iterators\n","\n","train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.response),\n","                            device=device, train=True, sort=True, sort_within_batch=True)\n","valid_iter = BucketIterator(valid, batch_size=16, sort_key=lambda x: len(x.response),\n","                            device=device, train=True, sort=True, sort_within_batch=True)\n","test_iter = Iterator(test, batch_size=16, device=device, train=False, shuffle=False, sort=False)\n","test_final_iter = Iterator(test_final, batch_size=16, device=device, train=False, shuffle=False, sort=False)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYJrK3uOLB0H","executionInfo":{"status":"ok","timestamp":1606896731405,"user_tz":-540,"elapsed":627,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}}},"source":["class BERT(nn.Module):\n","\n","    def __init__(self):\n","        super(BERT, self).__init__()\n","\n","        options_name = \"bert-base-uncased\"\n","        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n","\n","    def forward(self, text, label):\n","        loss, text_fea = self.encoder(text, labels=label)[:2]\n","\n","        return loss, text_fea"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y16facaULEDX","executionInfo":{"status":"ok","timestamp":1606896735069,"user_tz":-540,"elapsed":717,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}}},"source":["# Save and Load Functions\n","\n","def save_checkpoint(save_path, model, valid_loss):\n","\n","    if save_path == None:\n","        return\n","    \n","    state_dict = {'model_state_dict': model.state_dict(),\n","                  'valid_loss': valid_loss}\n","    \n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","def load_checkpoint(load_path, model):\n","    \n","    if load_path==None:\n","        return\n","    \n","    state_dict = torch.load(load_path, map_location=device)\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    model.load_state_dict(state_dict['model_state_dict'])\n","    return state_dict['valid_loss']\n","\n","\n","def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n","\n","    if save_path == None:\n","        return\n","    \n","    state_dict = {'train_loss_list': train_loss_list,\n","                  'valid_loss_list': valid_loss_list,\n","                  'global_steps_list': global_steps_list}\n","    \n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","\n","def load_metrics(load_path):\n","\n","    if load_path==None:\n","        return\n","    \n","    state_dict = torch.load(load_path, map_location=device)\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"dskFzOyALG4p"},"source":["# Training Function\n","\n","def train(model,\n","          optimizer,\n","          criterion = nn.BCELoss(),\n","          train_loader = train_iter,\n","          valid_loader = valid_iter,\n","          num_epochs = 5,\n","          eval_every = len(train_iter) // 2,\n","          file_path = '/content',\n","          best_valid_loss = float(\"Inf\")):\n","    \n","    # initialize running values\n","    running_loss = 0.0\n","    valid_running_loss = 0.0\n","    global_step = 0\n","    train_loss_list = []\n","    valid_loss_list = []\n","    global_steps_list = []\n","\n","    # training loop\n","    model.train()\n","    for epoch in range(num_epochs):\n","        for (labels, responses), _ in train_loader:\n","            labels = labels.type(torch.LongTensor)           \n","            labels = labels.to(device)\n","            responses = responses.type(torch.LongTensor)  \n","            responses = responses.to(device)\n","            output = model(responses, labels)\n","            loss, _ = output\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # update running values\n","            running_loss += loss.item()\n","            global_step += 1\n","\n","            # evaluation step\n","            if global_step % eval_every == 0:\n","                model.eval()\n","                with torch.no_grad():                    \n","\n","                    # validation loop\n","                    for (labels, responses), _ in valid_loader:\n","                        labels = labels.type(torch.LongTensor)           \n","                        labels = labels.to(device)\n","                        responses = responses.type(torch.LongTensor)  \n","                        responses = responses.to(device)\n","                        output = model(responses, labels)\n","                        loss, _ = output\n","                        \n","                        valid_running_loss += loss.item()\n","\n","                # evaluation\n","                average_train_loss = running_loss / eval_every\n","                average_valid_loss = valid_running_loss / len(valid_loader)\n","                train_loss_list.append(average_train_loss)\n","                valid_loss_list.append(average_valid_loss)\n","                global_steps_list.append(global_step)\n","\n","                # resetting running values\n","                running_loss = 0.0                \n","                valid_running_loss = 0.0\n","                model.train()\n","\n","                # print progress\n","                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n","                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n","                              average_train_loss, average_valid_loss))\n","                \n","                # checkpoint\n","                if best_valid_loss > average_valid_loss:\n","                    best_valid_loss = average_valid_loss\n","                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n","                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n","    \n","    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n","    print('Finished Training!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"id":"4ooIikDbLn61","executionInfo":{"status":"error","timestamp":1606896743880,"user_tz":-540,"elapsed":4472,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}},"outputId":"df053f0a-b9fb-45d9-94bb-683cded45581"},"source":["model = BERT().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=2e-5)\n","\n","train(model=model, optimizer=optimizer)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-e4474bff9c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'TabularDataset' object is not callable"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"Dwu2saGxRsI_","executionInfo":{"elapsed":1844,"status":"error","timestamp":1606796849035,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"},"user_tz":-540},"outputId":"cffc5399-0a49-4475-bebd-bf4d403ed160"},"source":["train_loss_list, valid_loss_list, global_steps_list = load_metrics('/content/metrics.pt')\n","plt.plot(global_steps_list, train_loss_list, label='Train')\n","plt.plot(global_steps_list, valid_loss_list, label='Valid')\n","plt.xlabel('Global Steps')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show() "],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-4cdd2acec57b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_steps_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/metrics.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_steps_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_steps_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Global Steps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_metrics' is not defined"]}]},{"cell_type":"code","metadata":{"id":"CBYOWX14R0f9","executionInfo":{"status":"ok","timestamp":1606896846278,"user_tz":-540,"elapsed":779,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}}},"source":["# Evaluation Function\n","\n","def evaluate(model, test_loader):\n","    y_pred = []\n","    y_true = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for (labels, responses), _ in test_loader:\n","\n","                labels = labels.type(torch.LongTensor)           \n","                labels = labels.to(device)\n","                responses = responses.type(torch.LongTensor)  \n","                responses = responses.to(device)\n","                output = model(responses, labels)\n","\n","                _, output = output\n","                y_pred.extend(torch.argmax(output, 1).tolist())\n","                y_true.extend(labels.tolist())\n","    \n","    print('Classification Report:')\n","    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n","    \n","    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n","    ax= plt.subplot()\n","    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n","\n","    ax.set_title('Confusion Matrix')\n","\n","    ax.set_xlabel('Predicted Labels')\n","    ax.set_ylabel('True Labels')\n","\n","    ax.xaxis.set_ticklabels(['not-sarc', 'sarc'])\n","    ax.yaxis.set_ticklabels(['not-sarc', 'sarc'])\n","\n","def evaluate_class(model, test_loader):\n","    y_pred = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for (labels, responses), _ in test_loader:\n","\n","                labels = labels.type(torch.LongTensor)           \n","                labels = labels.to(device)\n","                responses = responses.type(torch.LongTensor)  \n","                responses = responses.to(device)\n","                output = model(responses, labels)\n","\n","                _, output = output\n","                y_pred.extend(torch.argmax(output, 1).tolist())\n","    \n","    results = []\n","    for i in range(0, len(y_pred)):\n","      if (y_pred[i] == 1):\n","        results.append(\"twitter_\" + str(i+1) + \",\" + \"SARCASM\")\n","      else:\n","        results.append(\"twitter_\" + str(i+1) + \",\" + \"NOT_SARCASM\")\n","    \n","    sep = \"\\n\"\n","    new_lines = sep.join(results)\n","    with open(\"/content/drive/MyDrive/answer.txt\", \"w\") as file:\n","      file.writelines(new_lines)\n","  "],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDlTB_AjSBLA","executionInfo":{"status":"ok","timestamp":1606896867504,"user_tz":-540,"elapsed":18731,"user":{"displayName":"Jongwoo Jeon","photoUrl":"","userId":"01461130194659869718"}},"outputId":"6ec1bd9f-6da7-4932-edf5-424ed3650de1"},"source":["best_model = BERT().to(device)\n","\n","load_checkpoint('/content/drive/MyDrive/model.pt', best_model)\n","\n","# evaluate(best_model, test_iter)\n","evaluate_class(best_model, test_final_iter)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Model loaded from <== /content/drive/MyDrive/model.pt\n"],"name":"stdout"}]}]}